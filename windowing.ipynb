{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":53666,"databundleVersionId":6589269,"sourceType":"competition"},{"sourceId":7068832,"sourceType":"datasetVersion","datasetId":4070598},{"sourceId":7087924,"sourceType":"datasetVersion","datasetId":4083964}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [CMI-SleepState-Detection](https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states/overview)\n## Child Mind Institute - Detect Sleep States\n### Detect sleep onset and wake from wrist-worn accelerometer data\n_______________________________________________________________________ \n# Author Details:\n- Name: Najeeb Haider Zaidi\n- Email: zaidi.nh@gmail.com\n- Profiles: [Github](https://github.com/snajeebz)  [LinkedIn](https://www.linkedin.com/in/najeebz) [Kaggle](https://www.kaggle.com/najeebz)\n- License: Private, Unlicensed, All the files in this repository under any branch are Prohibited to be used commercially or for personally, communally or privately unless permitted by author in writing.\n- Copyrights 2023-2024 (c) are reserved only by the author: Najeeb Haider Zaidi\n________________________________________________________________________\n# Attributions:\nThe Dataset has been provided by Child Mind Institute. in [Kaggle Competition](https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states/overview) which the author is participating in and authorized to use the dataset solely for the competition purposes.\n________________________________________________________________________","metadata":{}},{"cell_type":"code","source":"!pip install pandarallel\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:37:49.359177Z","iopub.execute_input":"2023-12-04T11:37:49.359563Z","iopub.status.idle":"2023-12-04T11:38:04.587176Z","shell.execute_reply.started":"2023-12-04T11:37:49.359529Z","shell.execute_reply":"2023-12-04T11:38:04.585848Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandarallel in /opt/conda/lib/python3.10/site-packages (1.6.5)\nRequirement already satisfied: dill>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from pandarallel) (0.3.7)\nRequirement already satisfied: pandas>=1 in /opt/conda/lib/python3.10/site-packages (from pandarallel) (2.0.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from pandarallel) (5.9.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2023.3)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (1.24.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1->pandarallel) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd# data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n#from pandarallel import pandarallel\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom datetime import datetime as dts\npd.set_option('display.max_row', 500)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_colwidth', None)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom tqdm import tqdm\ntqdm.pandas()\n#pandarallel.initialize(progress_bar=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:27:04.092173Z","iopub.execute_input":"2023-12-04T12:27:04.092630Z","iopub.status.idle":"2023-12-04T12:27:07.370225Z","shell.execute_reply.started":"2023-12-04T12:27:04.092584Z","shell.execute_reply":"2023-12-04T12:27:07.368821Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\n/kaggle/input/child-mind-institute-detect-sleep-states/sample_submission.csv\n/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\n/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"events=pd.read_csv('/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_full=pd.read_pickle('/kaggle/input/later-data/full_clustered .pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing the relationshiip between sleep and cluster","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def inactive_periods(df):\n    print(\"shape before application: \",df.shape)\n    df['diff_anglez']=df['anglez'].diff()\n    df=df[(df['enmo']!=0.0) | (df['diff_anglez']!=0.0)]\n    print(\"shape after application: \",df.shape)\n    df.drop('diff_anglez', inplace=True, axis=1)\n    print(\"shape after completion: \",df.shape)\n    print(\"removed \")\n    return df\ndef clustering(df):\n    from sklearn.cluster import KMeans\n    from sklearn.preprocessing import StandardScaler    \n    X=df[['anglez','enmo']]\n#Scalling the data\n    scaler=StandardScaler()\n    X_scaled=scaler.fit_transform(X)\n#perform clustering\n    model=KMeans(n_clusters=4,algorithm=\"elkan\" )\n    model.fit(X_scaled)\n    return model.labels_\ndef rollingstd(series_df):\n# Creating columns with nans\n    series_df['sd_enmo_1']=np.nan    # 1 min rolling std: enmo\n    series_df['sd_anglez_1']=np.nan  # 1 min rolling std: anglez\n    series_df['m_enmo_2']=np.nan     # 2 min rolling mean: enmo\n    series_df['m_anglez_2']=np.nan   # 2 min rolling std: anglez \n    print('anglez rolling std 12')\n    series_df['sd_anglez_1'] = (series_df.groupby('series_id')['anglez']\n                      .rolling(12)\n                      .std()\n                      .reset_index(level=0, drop=True))\n    print('anglez rolling std 2')\n    series_df['sd_anglez_1'][series_df['sd_anglez_1'].isna()==True] = (series_df.groupby('series_id')['anglez']\n                      .rolling(2)\n                      .std()\n                      .reset_index(level=0, drop=True))\n    print('enmo rolling std 12')\n    series_df['sd_enmo_1'] = (series_df.groupby('series_id')['enmo']\n                      .rolling(12)\n                      .std()\n                      .reset_index(level=0, drop=True))\n    print('enmo rolling mean 24')\n    series_df['m_enmo_2'] = (series_df.groupby('series_id')['enmo']\n                      .rolling(24)\n                      .mean()\n                      .reset_index(level=0, drop=True))\n    print('anglez rolling mean 24')\n    series_df['m_anglez_2'] = (series_df.groupby('series_id')['anglez']\n                      .rolling(24)\n                      .mean()\n                      .reset_index(level=0, drop=True))\n    print('enmo rolling std 2')\n    print('Nans in sd_emno_1: ',series_df['sd_enmo_1'].isnull().sum())\n    series_df['sd_enmo_1'][series_df['sd_enmo_1'].isna()==True] = (series_df.groupby('series_id')['enmo']\n                      .rolling(2)\n                      .std()\n                      .reset_index(level=0, drop=True))\n    print('enmo rolling mean 2')\n    series_df['m_enmo_2'][series_df['m_enmo_2'].isna()==True] = (series_df.groupby('series_id')['enmo']\n                      .rolling(2)\n                      .mean()\n                      .reset_index(level=0, drop=True))\n    print('anglez rolling mean 2')\n    series_df['m_anglez_2'][series_df['m_anglez_2'].isna()==True] = (series_df.groupby('series_id')['anglez']\n                      .rolling(2)\n                      .mean()\n                      .reset_index(level=0, drop=True))\n#Series wise rolling std and mean\n# filling rest of nans\n    print('Nans in sd_emno_1: ',series_df['sd_enmo_1'].isnull().sum())\n    series_df['sd_enmo_1'].fillna(0.0, inplace=True)\n    series_df['sd_anglez_1'].fillna(0.0, inplace=True)\n    series_df['m_enmo_2'].fillna(0.0, inplace=True)\n    series_df['m_anglez_2'].fillna(0.0, inplace=True)\n    print('Nans after removal: ',series_df['sd_enmo_1'].isnull().sum())\n\n    return(series_df)\ndef scale(X):\n    from sklearn import preprocessing\n    scaler=preprocessing.StandardScaler().fit(X)\n    return (scaler.transform(X))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:28:25.021368Z","iopub.execute_input":"2023-12-04T12:28:25.021812Z","iopub.status.idle":"2023-12-04T12:28:25.044569Z","shell.execute_reply.started":"2023-12-04T12:28:25.021775Z","shell.execute_reply":"2023-12-04T12:28:25.043337Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Importing the datasets\nprint('Importing Training Datasets')\ndf_series=pd.read_parquet(path=\"/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\", engine='auto')\ndf_events=pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\")\nprint('Dataset Imported...')\nprint('______________________________________')\n\n# Merging the datasets\nprint('Merging the training datasets...')\nevents=df_events[['series_id', 'step','event']]\nseries_df=pd.merge(df_series,events,on=[\"step\",\"series_id\"],how='left')\ndf_series=[]\nseries_df['sleep']=np.nan\nseries_df.loc[series_df[\"event\"]==\"onset\", \"sleep\"] = 1\nseries_df.loc[series_df[\"event\"]==\"wakeup\", \"sleep\"] = 0\nseries_df['sleep'].fillna(method='ffill', inplace=True)\nseries_df['sleep'].fillna(value=0, inplace=True)\nprint('Datasets Merged...')\nprint('______________________________________')\n\n# Removing the periods of inactivity\nprint('Removing the periods of Inactivity...')\nseries_df=inactive_periods(series_df)\nprint('______________________________________')\n\n# Forming Windows\nwin_size=720  #600mins\nprint('Creating Windows each size: ',win_size)\n#series_df=window(series_df,win_size)\nprint('Windows formed...')\nprint('______________________________________')\n\n# Adding the columns of Standard Deviation (1 min)\nprint('Adding columns to account for deviation in enmo and anglez 1 min rolling...')\nseries_df=rollingstd(series_df)\nseries_df['sd_anglez_1']=pd.to_numeric(series_df['sd_anglez_1'])\nseries_df['sd_enmo_1']=pd.to_numeric(series_df['sd_enmo_1'])\nseries_df['m_anglez_2']=pd.to_numeric(series_df['m_anglez_2'])\nseries_df['m_enmo_2']=pd.to_numeric(series_df['m_enmo_2'])\nprint('Std columns added...')\nprint('______________________________________')\n\n# Clustering the Data\nprint('Clustering the data based on enmo and anglez...')\nseries_df['cluster']=(clustering(series_df)+1)/4\nprint('Added clusters...')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:28:35.030598Z","iopub.execute_input":"2023-12-04T12:28:35.031092Z","iopub.status.idle":"2023-12-04T12:57:07.689410Z","shell.execute_reply.started":"2023-12-04T12:28:35.031052Z","shell.execute_reply":"2023-12-04T12:57:07.687881Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Importing Training Datasets\nDataset Imported...\n______________________________________\nMerging the training datasets...\nDatasets Merged...\n______________________________________\nRemoving the periods of Inactivity...\nshape before application:  (127946340, 7)\nshape after application:  (111766109, 8)\nshape after completion:  (111766109, 7)\nremoved \n______________________________________\nCreating Windows each size:  720\nWindows formed...\n______________________________________\nAdding columns to account for deviation in enmo and anglez 1 min rolling...\nanglez rolling std 12\nanglez rolling std 2\nenmo rolling std 12\nenmo rolling mean 24\nanglez rolling mean 24\nenmo rolling std 2\nNans in sd_emno_1:  3047\nenmo rolling mean 2\nanglez rolling mean 2\nNans in sd_emno_1:  277\nNans after removal:  0\nStd columns added...\n______________________________________\nClustering the data based on enmo and anglez...\nAdded clusters...\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX=series_df[['sd_anglez_1','sd_enmo_1','anglez','m_anglez_2','m_enmo_2','enmo','cluster']]\ny=series_df[['sleep']]\nseries_df=[]\nX_scaled=scale(X)\nX_train, X_test, y_train, y_test =train_test_split(X_scaled,y,test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:57:07.692664Z","iopub.execute_input":"2023-12-04T12:57:07.693076Z","iopub.status.idle":"2023-12-04T12:58:34.520149Z","shell.execute_reply.started":"2023-12-04T12:57:07.693029Z","shell.execute_reply":"2023-12-04T12:58:34.518878Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def evaluate(y_test,ypred):\n    from sklearn.metrics import precision_score\n    from sklearn.metrics import recall_score\n    from sklearn.metrics import f1_score\n    from sklearn.metrics import accuracy_score\n    from sklearn.metrics import confusion_matrix\n    print(\"Accuracy: \",accuracy_score(y_test,y_pred)) \n    print(\"Precision Score : \", precision_score(y_test,y_pred)) #precision measures the proportion of true positive predictions among all positive instances. how many of survived predicted actually survived, doesn't verifies 0's 70 survived as preicted whereas actually 92 survived so 70/92 will be the precision.  if we predicted 70 survived, so presion will tell how many of those 70 predicted survived matches the actual row by row data. It checkes all positives and verifies if the answer is true for each row?\n    print(\"Recall Score: \", recall_score(y_test,y_pred, average='macro')) #Recall measures the proportion of true positive predictions among all actual positive instalnces. If we predicted 100 survived correctly whereas actually 100 survived out of which 67 predicted correctly so recall will be 0.67\n    print(\"F1 Score: \",f1_score(y_test,y_pred)) #mean of recall and precision\n    cm = confusion_matrix(y_test, y_pred)\n    figure= px.imshow(cm,text_auto=True, width=1200, height=1200)\n    figure.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:58:34.522152Z","iopub.execute_input":"2023-12-04T12:58:34.522627Z","iopub.status.idle":"2023-12-04T12:58:34.531455Z","shell.execute_reply.started":"2023-12-04T12:58:34.522579Z","shell.execute_reply":"2023-12-04T12:58:34.530367Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf =RandomForestClassifier(n_jobs=-1,verbose=1) \nprint ('Training the model')\nrf.fit(X_train,y_train)\nprint ('Saving the model')\nfrom joblib import dump, load\ndump(rf, 'rf_model.joblib')\ny_pred=rf.predict(X_test)\nevaluate(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:58:34.533967Z","iopub.execute_input":"2023-12-04T12:58:34.534666Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Training the model\n","output_type":"stream"}]},{"cell_type":"code","source":"df_sleep=df.loc[df['sleep']==1]\ndf_onset=df.loc[df['sleep']==0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sleep['cluster'].mode()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_onset['cluster'].mode()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df['timestamp']=df['timestamp'].parallel_apply(lambda x: pd.to_datetime(x,utc=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_pickel('cluster_timestamped.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"events","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"events['step'].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"event_df=events.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"event_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['window']=np.nan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ind=df.index[df['event'].isna()==False]\nprint(ind)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 30 min window on change event, with single timestep:5sec. \nc=0\nfor i in tqdm(ind):\n    a=i-360\n    b=i+360\n    df['window'].loc[a:i]=int(c)\n    c=c+1\n    df['window'].loc[i:b]=int(c)\n    c=c+1\nprint('Windows Created: ', c)    \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df[df['window'].isna()==False]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['timestamp']=df['timestamp'].parallel_apply(lambda x: pd.to_datetime(x,utc=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adding rolling Deviation","metadata":{}},{"cell_type":"code","source":"def prepare(df):\n    df['sd_anglez_1']=pd.to_numeric(df['anglez'].rolling(window=12).std())\n    df['sd_enmo_1']=pd.to_numeric(df['enmo'].rolling(window=12).std())\n    df['sd_anglez_1'].fillna('0.0',inplace=True)\n    df['sd_enmo_1'].fillna('0.0',inplace=True)\n    df['sleep'] = df['sleep'].replace({0:False, 0.2:True})\n    return(df)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T06:52:05.360864Z","iopub.execute_input":"2023-11-30T06:52:05.361274Z","iopub.status.idle":"2023-11-30T06:52:05.368045Z","shell.execute_reply.started":"2023-11-30T06:52:05.361240Z","shell.execute_reply":"2023-11-30T06:52:05.367020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analyzing the windows","metadata":{}},{"cell_type":"code","source":"def visualization(df_n):\n    for i in range(10):\n        title=\"Sleep: \"+ str(df_n['sleep'][df_n['window']==i].mean())\n        fig=px.line(y=df_n['sleep'][df_n['window']==i],x=df_n['timestamp'][df_n['window']==i])\n        fig.add_scatter(y=df_n['cluster'][df_n['window']==i],x=df_n['timestamp'][df_n['window']==i], name='cluster')\n        fig.add_scatter(y=df_n['enmo'][df_n['window']==i],x=df_n['timestamp'][df_n['window']==i], name='sleep')\n        fig.update_layout(title=title)\n        fig.show()\nvisualization(df)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T06:43:16.303788Z","iopub.execute_input":"2023-11-30T06:43:16.304905Z","iopub.status.idle":"2023-11-30T06:43:16.312004Z","shell.execute_reply.started":"2023-11-30T06:43:16.304865Z","shell.execute_reply":"2023-11-30T06:43:16.310864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate Prediction","metadata":{}},{"cell_type":"code","source":"def evaluate(y_test,ypred):\n    from sklearn.metrics import precision_score\n    from sklearn.metrics import recall_score\n    from sklearn.metrics import f1_score\n    from sklearn.metrics import accuracy_score\n    from sklearn.metrics import confusion_matrix\n    print(\"Accuracy: \",accuracy_score(y_test,y_pred)) \n    print(\"Precision Score : \", precision_score(y_test,y_pred)) #precision measures the proportion of true positive predictions among all positive instances. how many of survived predicted actually survived, doesn't verifies 0's 70 survived as preicted whereas actually 92 survived so 70/92 will be the precision.  if we predicted 70 survived, so presion will tell how many of those 70 predicted survived matches the actual row by row data. It checkes all positives and verifies if the answer is true for each row?\n    print(\"Recall Score: \", recall_score(y_test,y_pred, average='macro')) #Recall measures the proportion of true positive predictions among all actual positive instalnces. If we predicted 100 survived correctly whereas actually 100 survived out of which 67 predicted correctly so recall will be 0.67\n    print(\"F1 Score: \",f1_score(y_test,y_pred)) #mean of recall and precision\n    cm=confusion_matrix(y_test, y_pred)\n    figure= px.imshow(cm,text_auto=True, width=1200, height=1200)\n    figure.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T06:43:38.038004Z","iopub.execute_input":"2023-11-30T06:43:38.039384Z","iopub.status.idle":"2023-11-30T06:43:38.047856Z","shell.execute_reply.started":"2023-11-30T06:43:38.039326Z","shell.execute_reply":"2023-11-30T06:43:38.046448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(df['sleep']).describe().transpose()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df.to_pickle('ts_win_60_diff.pkl')\npath=\"/kaggle/input/60min-window-before-and-after-the-event/ts_win_60_diff-30.pkl\"\ndf=prepare(pd.read_pickle(path))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T06:52:14.342355Z","iopub.execute_input":"2023-11-30T06:52:14.342773Z","iopub.status.idle":"2023-11-30T06:52:19.659137Z","shell.execute_reply.started":"2023-11-30T06:52:14.342739Z","shell.execute_reply":"2023-11-30T06:52:19.658141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T06:52:27.530763Z","iopub.execute_input":"2023-11-30T06:52:27.531147Z","iopub.status.idle":"2023-11-30T06:52:27.545574Z","shell.execute_reply.started":"2023-11-30T06:52:27.531117Z","shell.execute_reply":"2023-11-30T06:52:27.543969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nX=df[['sd_anglez_1','sd_enmo_1','anglez','enmo','cluster']]\ny=df[['sleep']]\n#scaler=preprocessing.StandardScaler().fit(X)\n#X_scaled = scaler.transform(X)\nX_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T08:04:47.543610Z","iopub.execute_input":"2023-11-30T08:04:47.544037Z","iopub.status.idle":"2023-11-30T08:04:52.256122Z","shell.execute_reply.started":"2023-11-30T08:04:47.544006Z","shell.execute_reply":"2023-11-30T08:04:52.254498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_scaled","metadata":{"execution":{"iopub.status.busy":"2023-11-30T08:03:52.411183Z","iopub.execute_input":"2023-11-30T08:03:52.411668Z","iopub.status.idle":"2023-11-30T08:03:52.422163Z","shell.execute_reply.started":"2023-11-30T08:03:52.411632Z","shell.execute_reply":"2023-11-30T08:03:52.420807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Model","metadata":{}},{"cell_type":"code","source":"f\ny_pred=model.predict(X_test)\nevaluate(y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf =RandomForestClassifier(n_jobs=-1,verbose=1) \nprint ('Training the model')\nrf.fit(X_train,y_train)\nprint ('Saving the model')\nfrom joblib import dump, load\ndump(rf, 'rf_model.joblib')\ny_pred=rf.predict(X_test)\nevaluate(y_test,y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T08:05:04.589346Z","iopub.execute_input":"2023-11-30T08:05:04.589790Z","iopub.status.idle":"2023-11-30T08:33:06.476909Z","shell.execute_reply.started":"2023-11-30T08:05:04.589750Z","shell.execute_reply":"2023-11-30T08:33:06.475606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvm = SVC(verbose=1) # n_neighbors is the number of neighbors to consider when predicting a class label for\nsvm.fit(X_test,y_test)\ny_pred=svm.predict(X_test)\nevaluate(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T08:42:24.608415Z","iopub.execute_input":"2023-11-30T08:42:24.608941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Naive Bayes Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB() \nnb.fit(X_train,y_train)\n#dump(nb, 'nb_model.joblib')\ny_pred=nb.predict(X_test)\nevaluate(y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNN Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=10,n_jobs=-1,verbose=1) # n_neighbors is the number of neighbors to consider when predicting a class label for\nknn.fit(X_train,y_train)\n#dump(knn, 'knn_model.joblib')\ny_pred=knn.predict(X_test)\nevaluate(y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred['predicted']=y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"X.describe()","metadata":{}}]}