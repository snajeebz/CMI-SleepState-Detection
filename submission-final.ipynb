{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":53666,"databundleVersionId":6589269,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing and Importing and Initializing Libraries.","metadata":{}},{"cell_type":"code","source":"!pip install pandarallel","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd# data processing, CSV file I/O (e.g. pd.read_csv)\n#from pandarallel import pandarallel\nimport plotly.express as px\nimport matplotlib.pyplot as plt\npd.set_option('display.max_row', 500)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_colwidth', None)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom tqdm import tqdm\ntqdm.pandas()\n#pandarallel.initialize(progress_bar=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-01T06:10:27.565922Z","iopub.execute_input":"2023-12-01T06:10:27.566519Z","iopub.status.idle":"2023-12-01T06:10:29.140198Z","shell.execute_reply.started":"2023-12-01T06:10:27.566475Z","shell.execute_reply":"2023-12-01T06:10:29.138765Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\n/kaggle/input/child-mind-institute-detect-sleep-states/sample_submission.csv\n/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\n/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Reading the Datasets.","metadata":{}},{"cell_type":"code","source":"df_series=pd.read_parquet(path=\"/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\", engine='auto')","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:10:43.344058Z","iopub.execute_input":"2023-12-01T06:10:43.344748Z","iopub.status.idle":"2023-12-01T06:11:54.511129Z","shell.execute_reply.started":"2023-12-01T06:10:43.344704Z","shell.execute_reply":"2023-12-01T06:11:54.509895Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_events=pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\")\nevents=df_events[['series_id', 'step','event']]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:12:03.096186Z","iopub.execute_input":"2023-12-01T06:12:03.097640Z","iopub.status.idle":"2023-12-01T06:12:03.128942Z","shell.execute_reply.started":"2023-12-01T06:12:03.097590Z","shell.execute_reply":"2023-12-01T06:12:03.127660Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Merging the Datasets to train the model","metadata":{}},{"cell_type":"code","source":"series_df=pd.merge(df_series,events,on=[\"step\",\"series_id\"],how='left')\nseries_df['sleep']=np.nan\nseries_df.loc[series_df[\"event\"]==\"onset\", \"sleep\"] = 1\nseries_df.loc[series_df[\"event\"]==\"wakeup\", \"sleep\"] = 0\nseries_df['sleep'].fillna(method='ffill', inplace=True)\nseries_df['sleep'].fillna(value=0, inplace=True)\ndf_series=[]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:12:10.347762Z","iopub.execute_input":"2023-12-01T06:12:10.348222Z","iopub.status.idle":"2023-12-01T06:14:19.863767Z","shell.execute_reply.started":"2023-12-01T06:12:10.348180Z","shell.execute_reply":"2023-12-01T06:14:19.862270Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"series_df","metadata":{"execution":{"iopub.status.busy":"2023-11-30T20:56:12.526013Z","iopub.execute_input":"2023-11-30T20:56:12.526419Z","iopub.status.idle":"2023-11-30T20:56:12.557809Z","shell.execute_reply.started":"2023-11-30T20:56:12.526381Z","shell.execute_reply":"2023-11-30T20:56:12.556722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Windowing the training data\n### As the target is to detect an event, \n### So, extracting timesteps 30 min before and after the events. ","metadata":{}},{"cell_type":"code","source":"def window(df, win_size):\n    ind=df.index[df['event'].isna()==False]\n    c=0\n    df['window']=np.nan\n    for i in tqdm(ind):\n        a=i-win_size\n        b=i+win_size\n        df['window'].loc[a:i]=int(c)\n        c=c+1\n        df['window'].loc[i:b]=int(c)\n        c=c+1\n    df['window'].dropna(inplace=True)\n    return df[df['window'].isna()==False]\nwin_size=360\ndf_series=window(series_df,win_size)\n#df_series=df_series[df_series['window'].isna()==False]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:14:19.866633Z","iopub.execute_input":"2023-12-01T06:14:19.867485Z","iopub.status.idle":"2023-12-01T06:14:36.143467Z","shell.execute_reply.started":"2023-12-01T06:14:19.867433Z","shell.execute_reply":"2023-12-01T06:14:36.142075Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|██████████| 9585/9585 [00:09<00:00, 1056.92it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"df_series","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:42:30.148051Z","iopub.execute_input":"2023-11-30T21:42:30.148533Z","iopub.status.idle":"2023-11-30T21:42:30.152848Z","shell.execute_reply.started":"2023-11-30T21:42:30.148496Z","shell.execute_reply":"2023-11-30T21:42:30.151962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clustering the Enmo and Anglez","metadata":{}},{"cell_type":"code","source":"def clustering(df):\n    from sklearn.cluster import KMeans\n    from sklearn.preprocessing import StandardScaler    \n    X=df[['anglez','enmo']]\n#Scalling the data\n    scaler=StandardScaler()\n    X_scaled=scaler.fit_transform(X)\n#perform clustering\n    model=KMeans(n_clusters=4 )\n    model.fit(X_scaled)\n    return model.labels_\ndf_series['cluster']=(clustering(df_series)+1)/4","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:14:36.144815Z","iopub.execute_input":"2023-12-01T06:14:36.145204Z","iopub.status.idle":"2023-12-01T06:15:14.337189Z","shell.execute_reply.started":"2023-12-01T06:14:36.145169Z","shell.execute_reply":"2023-12-01T06:15:14.336050Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Adding Rolling Standard Deviations\n\n- As per observation enmo and anglez varies frequently and more than normal for few timesteps before and after the event.\n- In order to consider the variations into the modelling, using the method.","metadata":{}},{"cell_type":"code","source":"def rollingstd(df):\n    df['sd_anglez_1']=pd.to_numeric(df['anglez'].rolling(window=12).std())\n    df['sd_enmo_1']=pd.to_numeric(df['enmo'].rolling(window=12).std())\n    df['sd_anglez_1'].fillna('0.0',inplace=True)\n    df['sd_enmo_1'].fillna('0.0',inplace=True)\n   # df['sleep'] = df['sleep'].replace({0:False, 1:True})\n    return(df)\nseries_df=rollingstd(df_series)\nseries_df['sd_anglez_1']=pd.to_numeric(series_df['sd_anglez_1'])\nseries_df['sd_enmo_1']=pd.to_numeric(series_df['sd_anglez_1'])\nseries_df[['sleep']]=series_df[['sleep']].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:15:14.339825Z","iopub.execute_input":"2023-12-01T06:15:14.340189Z","iopub.status.idle":"2023-12-01T06:15:20.479433Z","shell.execute_reply.started":"2023-12-01T06:15:14.340157Z","shell.execute_reply":"2023-12-01T06:15:20.477686Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"series_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-11-30T22:06:21.217750Z","iopub.execute_input":"2023-11-30T22:06:21.218267Z","iopub.status.idle":"2023-11-30T22:06:21.228152Z","shell.execute_reply.started":"2023-11-30T22:06:21.218227Z","shell.execute_reply":"2023-11-30T22:06:21.226686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nX=series_df[['sd_anglez_1','sd_enmo_1','anglez','enmo','cluster']]\ny=series_df[['sleep']]\nX_scaled=X\n#scaler=preprocessing.MinMaxScaler().fit(X)\n#X_scaled= scaler.transform(X)\nX_train, X_test, y_train, y_test =train_test_split(X_scaled,y,test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:15:20.480922Z","iopub.execute_input":"2023-12-01T06:15:20.481319Z","iopub.status.idle":"2023-12-01T06:15:22.860611Z","shell.execute_reply.started":"2023-12-01T06:15:20.481267Z","shell.execute_reply":"2023-12-01T06:15:22.859380Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-11-30T22:06:54.498745Z","iopub.execute_input":"2023-11-30T22:06:54.499189Z","iopub.status.idle":"2023-11-30T22:06:54.507971Z","shell.execute_reply.started":"2023-11-30T22:06:54.499154Z","shell.execute_reply":"2023-11-30T22:06:54.506721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf =RandomForestClassifier(n_jobs=-1,verbose=1) \nprint ('Training the model')\nrf.fit(X_train,y_train)\nprint ('Saving the model')\n#from joblib import dump, load\n#dump(rf, 'rf_model.joblib')\ny_pred=rf.predict(X_test)\nevaluate(y_test,y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape[1]\ninput_size=X_train.shape[1]*win_size\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:18:23.268895Z","iopub.execute_input":"2023-12-01T06:18:23.269373Z","iopub.status.idle":"2023-12-01T06:18:23.276333Z","shell.execute_reply.started":"2023-12-01T06:18:23.269335Z","shell.execute_reply":"2023-12-01T06:18:23.274979Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nmodel_nn=tf.keras.Sequential([\n  tf.keras.layers.Dense(360,input_shape=[X_train.shape[1]]),\n  tf.keras.layers.Dense(360,activation=tf.nn.leaky_relu, use_bias=True),\n  tf.keras.layers.Dense(180,activation=tf.nn.relu),\n  tf.keras.layers.Dense(90,activation=tf.nn.relu),\n  tf.keras.layers.Dense(20,activation=tf.nn.leaky_relu),\n  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),\n])\n#model_nn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001) , \n#                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n#                metrics=['accuracy'])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:22:57.395279Z","iopub.execute_input":"2023-12-01T06:22:57.396996Z","iopub.status.idle":"2023-12-01T06:22:57.517167Z","shell.execute_reply.started":"2023-12-01T06:22:57.396918Z","shell.execute_reply":"2023-12-01T06:22:57.515961Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"epochs = 50\nbatch_size = win_size\n\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\n        \"best_model.x\", save_best_only=True, monitor=\"val_loss\"\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=\"val_loss\", factor=0.5, patience=epochs, min_lr=0.0001\n    ),\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=epochs/10, verbose=1),\n]\nmodel_nn.compile(\n    optimizer=\"adam\",\n    #loss=\"sparse_categorical_crossentropy\",\n    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=['binary_accuracy'],\n)\nmodel_nn.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:24:40.876168Z","iopub.execute_input":"2023-12-01T06:24:40.877567Z","iopub.status.idle":"2023-12-01T06:24:40.918380Z","shell.execute_reply.started":"2023-12-01T06:24:40.877513Z","shell.execute_reply":"2023-12-01T06:24:40.916355Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_10 (Dense)            (None, 360)               2160      \n                                                                 \n dense_11 (Dense)            (None, 360)               129960    \n                                                                 \n dense_12 (Dense)            (None, 180)               64980     \n                                                                 \n dense_13 (Dense)            (None, 90)                16290     \n                                                                 \n dense_14 (Dense)            (None, 20)                1820      \n                                                                 \n dense_15 (Dense)            (None, 1)                 21        \n                                                                 \n=================================================================\nTotal params: 215231 (840.75 KB)\nTrainable params: 215231 (840.75 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-11-30T22:07:56.314602Z","iopub.execute_input":"2023-11-30T22:07:56.315157Z","iopub.status.idle":"2023-11-30T22:07:56.324321Z","shell.execute_reply.started":"2023-11-30T22:07:56.315113Z","shell.execute_reply":"2023-11-30T22:07:56.323055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model_nn.fit(\n    X_train,\n    y_train,\n    batch_size=360,\n    epochs=epochs,\n    callbacks=callbacks,\n    validation_split=0.2,\n    verbose=1,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:24:53.548709Z","iopub.execute_input":"2023-12-01T06:24:53.549182Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/50\n 7553/12286 [=================>............] - ETA: 49s - loss: 0.4219 - binary_accuracy: 0.8319","output_type":"stream"}]},{"cell_type":"code","source":"model = keras.models.load_model(\"best_model.x\")\n\ntest_loss, test_acc = model.evaluate(X_test, y_test)\n\nprint(\"Test accuracy\", test_acc)\nprint(\"Test loss\", test_loss)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric = \"sparse_categorical_accuracy\"\nplt.figure()\nplt.plot(history.history[metric])\nplt.plot(history.history[\"val_\" + metric])\nplt.title(\"model \" + metric)\nplt.ylabel(metric, fontsize=\"large\")\nplt.xlabel(\"epoch\", fontsize=\"large\")\nplt.legend([\"train\", \"val\"], loc=\"best\")\nplt.show()\nplt.close()","metadata":{},"execution_count":null,"outputs":[]}]}